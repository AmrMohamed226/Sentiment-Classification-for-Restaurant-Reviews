{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2254327",
   "metadata": {},
   "source": [
    "# DAT340 / DIT867 Applied Machine Learning\n",
    "## Programming assignment 3c: Text classification (Part 3)\n",
    "\n",
    "\n",
    "### Amr Mohamed\n",
    "#### Exchange student from CY Tech - France to GU CSE Department\n",
    "\n",
    "### Anh Thu DOAN\n",
    "#### Exchange student from CY Tech - France to GU CSE Department\n",
    "\n",
    "### Group PA3c 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c05da5da",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_12556/3129809809.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstanza\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexpon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\stanza\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstanza\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstanza\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstanza\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresources\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstanza\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresources\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstallation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minstall_corenlp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_corenlp_models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstanza\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__resources_version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\stanza\\pipeline\\core.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;31m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_lowrank\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msvd_lowrank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca_lowrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import stanza\n",
    "from scipy.stats import expon\n",
    "\n",
    "\n",
    "# the actual classification algorithm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# for splitting the dataset into training and test sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# for evaluating the quality of the classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "plt.style.use('bmh')\n",
    "plt.rcParams['image.cmap'] = 'Paired_r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('PA3_train.tsv', sep='\\t', names = ['annotation','review'], header=None) \n",
    "test = pd.read_csv('PA3_test_clean.tsv', sep='\\t', names = ['annotation','review'], header=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952776e7",
   "metadata": {},
   "source": [
    "# Training Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad76644",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4cc108",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.review[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4382d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['annotation1','annotation2']]=train.annotation.str.split('/', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c2f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb4e21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.annotation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97d902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.annotation1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddab8c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.annotation2.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97e595",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_disagreement = round(len(train[~train.annotation.isin(['1/1', '0/0'])].annotation)/len(train.annotation),3)\n",
    "print(\"The percentage of disagreement between the annotators is: \"+ str(total_disagreement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c984974",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_disagreement = round(len(train[train.annotation.isin(['1/0', '0/1'])].annotation)/len(train.annotation),3)\n",
    "print(\"The percentage of real disagreement between the annotators is (0/1 or 1/0): \"+ str(true_disagreement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f022bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_disagreement = round(len(train[~train.annotation.isin(['0/0', '1/1', '1/0', '0/1'])].annotation)/len(train.annotation),3)\n",
    "print(\"The percentage of misannotated reviews led to\\na difference in the annotations between the annotators is: \"+ str(false_disagreement))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532901a",
   "metadata": {},
   "source": [
    "## Sentiment analysis on rows with an annotation disagreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020a6632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stanza library for sentiment analysis\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize, sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c5d76a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# collecting the sentiment scores for instances with disagreement\n",
    "sent_scores = []\n",
    "cpt=0\n",
    "for index, row in train.iterrows():\n",
    "    if row.annotation in ['1/0', '-1/0', '-1/1', '0/1', '2/1', '2/0', '1/','9/1']:\n",
    "        doc = nlp(row.review)\n",
    "        for sentence in doc.sentences:\n",
    "            temp = []\n",
    "            temp.append(int(sentence.sentiment)-1)\n",
    "        sent_scores.append(sum(temp)/len(temp))\n",
    "        print(cpt, end='\\r')\n",
    "    else:\n",
    "        sent_scores.append(3)\n",
    "    cpt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c74e8d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['sent_ana']=sent_scores\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7692ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bce204",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[train.sent_ana!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b43f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sent_ana = train.sent_ana.replace(-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe2f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the correctly annotated instances by their annotations after the sentiment analysi\n",
    "train.loc[train['sent_ana'] == 3, 'sent_ana'] = train['annotation2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e78b7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.sent_ana = train.sent_ana.astype(int)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc6e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train[['review', 'sent_ana']]\n",
    "train_df=train_df.rename(columns={\"sent_ana\": \"annotation\"})\n",
    "train_df.annotation=pd.to_numeric(train_df.annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fb5399",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9a7eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df[train_df.annotation == 1].annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0ac307",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df[train_df.annotation == 0].annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e7804c",
   "metadata": {},
   "source": [
    "# Test data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d2742",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63758c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e2711",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.annotation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test.annotation== 1 ].annotation.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363477c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test[test.annotation== 0 ].annotation.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80864338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8fcae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the text by converting all words in all the reviews to lowercase letters\n",
    "def clean_text(text):\n",
    "    # filter to allow only alphabets\n",
    "#     text = re.sub(r'[^a-zA-Z\\']', ' ', text)\n",
    "    \n",
    "    # remove Unicode characters\n",
    "#     text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    \n",
    "    # convert to lowercase to maintain consistency\n",
    "    text = text.lower()\n",
    "       \n",
    "    return text\n",
    "\n",
    "train_df['review'] = train_df.review.apply(clean_text)\n",
    "test['review'] = test.review.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4247b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the training and testing sets\n",
    "X_train = (train_df.review)\n",
    "Y_train=train_df.annotation\n",
    "X_test = (test.review)\n",
    "Y_test=test.annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a3f0b1",
   "metadata": {},
   "source": [
    "# ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b33d9a",
   "metadata": {},
   "source": [
    "## Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c93af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy='most_frequent',random_state=0)\n",
    "pipeline = make_pipeline( TfidfVectorizer(), dummy)\n",
    "pipeline.fit(X_train, Y_train)\n",
    "accuracy_score(Y_test, pipeline.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bff9dc",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ca958",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVCpipeline = Pipeline( [(\n",
    "    'tfidf',TfidfVectorizer()), \n",
    "    ('linearsvc',LinearSVC(random_state=0))])\n",
    "LSVCpipeline.fit(X_train, Y_train)\n",
    "Yguess = LSVCpipeline.predict(X_test)\n",
    "accuracy_score(Y_test, Yguess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d911bd",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVCpipeline = Pipeline( [(\n",
    "    'tfidf',TfidfVectorizer()), \n",
    "    ('svc',SVC(random_state=0))])\n",
    "SVCpipeline.fit(X_train, Y_train)\n",
    "accuracy_score(Y_test, SVCpipeline.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576ded29",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d55e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logRpipeline = Pipeline( [(\n",
    "    'tfidf',TfidfVectorizer()), \n",
    "    ('logr',LogisticRegression(random_state=0))])\n",
    "pipeline.fit(X_train, Y_train)\n",
    "accuracy_score(Y_test, pipeline.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34908a73",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b43dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline( TfidfVectorizer(), GradientBoostingClassifier(random_state=0))\n",
    "pipeline.fit(X_train, Y_train)\n",
    "accuracy_score(Y_test, pipeline.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aab445",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96909b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline( TfidfVectorizer(), RandomForestClassifier(random_state=0))\n",
    "pipeline.fit(X_train, Y_train)\n",
    "accuracy_score(Y_test, pipeline.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635c7c2d",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f2fbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline( TfidfVectorizer(), MultinomialNB())\n",
    "pipeline.fit(X_train, Y_train)\n",
    "accuracy_score(Y_test, pipeline.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab0e0e",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae3c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NN = MLPClassifier(early_stopping=True,n_iter_no_change=10)\n",
    "pipeline = make_pipeline( TfidfVectorizer(),NN)\n",
    "pipeline.fit(X_train, Y_train)\n",
    "accuracy_score(Y_test, pipeline.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc911f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NN = MLPClassifier(alpha = 0.1, max_iter=400,early_stopping=True,n_iter_no_change=3)\n",
    "pipeline = make_pipeline( TfidfVectorizer(),NN)\n",
    "pipeline.fit(X_train, Y_train)\n",
    "accuracy_score(Y_test, pipeline.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b45ad61",
   "metadata": {},
   "source": [
    "# Highest scoring models Tuning and evaluation (SVC and Linear SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e922050",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b0a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparamaeter tuning\n",
    "LSVCpipeline = Pipeline( [(\n",
    "    'tfidf',TfidfVectorizer()), \n",
    "    ('linearsvc',LinearSVC(random_state=0))])\n",
    "\n",
    "param_grid = {'tfidf__max_df': [0.1,0.275,0.3545454545454545,0.3,0.5,0.75,1],\n",
    "            'linearsvc__loss': ['hinge','squared_hinge'],\n",
    "              'linearsvc__C': [0.01,0.1,1.0],\n",
    "             'linearsvc__penalty': ['l1','l2'],\n",
    "             'linearsvc__random_state': [0]}\n",
    " \n",
    "LSVCgrid = GridSearchCV(LSVCpipeline, param_grid,n_jobs=-1)\n",
    " \n",
    "# fitting the model for grid search\n",
    "LSVCgrid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d56477",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVCgrid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beffba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVCgrid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea88383a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(Y_test, LSVCgrid.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3667ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the max_df tfidf parameter values over the accuracies of the linearsvc model\n",
    "\n",
    "max_dfList=[]\n",
    "for i in list(np.linspace(0.1,1,100)): \n",
    "    LSVCpipeline = Pipeline( [(\n",
    "    'tfidf',TfidfVectorizer(max_df=i)), \n",
    "    ('svc',LinearSVC(random_state=0))])\n",
    "    LSVCpipeline.fit(X_train, Y_train)\n",
    "    max_dfList.append(accuracy_score(Y_test, LSVCpipeline.predict(X_test)))\n",
    "\n",
    "plt.plot(list(np.linspace(0.1,1,100)),max_dfList)\n",
    "plt.xlabel('TF-IDF max document frequency')\n",
    "plt.ylabel('LSVC accuracy score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c3076",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(max_dfList,list(np.linspace(0.1,1,100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609df858",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVCpipeline = Pipeline( [(\n",
    "    'tfidf',TfidfVectorizer(max_df=0.3545454545454545)), \n",
    "    ('linearsvc',LinearSVC(random_state=0))])\n",
    "LSVCpipeline.fit(X_train, Y_train)\n",
    "LSVC_Yguess = LSVCpipeline.predict(X_test)\n",
    "accuracy_score(Y_test, LSVC_Yguess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9da6105",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a7d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparamaeter tuning\n",
    "\n",
    "param_grid = {'tfidf__max_df': [0.2,0.225,0.275,0.3],\n",
    "              'svc__kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "              'svc__C': [0.3,0.5,0.7,1]}\n",
    "SVCgs = GridSearchCV(SVCpipeline, param_grid, n_jobs=-1)\n",
    "SVCgs.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3859561",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVCgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49ef339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVCgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906a9a3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(Y_test, SVCgs.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d389761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the max_df tfidf parameter values over the accuracies of the svc model\n",
    "max_dfList=[]\n",
    "for i in list(np.linspace(0.1,1,100)): \n",
    "    SVCpipeline = Pipeline( [(\n",
    "    'tfidf',TfidfVectorizer(max_df=i)), \n",
    "    ('svc',SVC(random_state=0))])\n",
    "    SVCpipeline.fit(X_train, Y_train)\n",
    "    max_dfList.append(accuracy_score(Y_test, SVCpipeline.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a1b44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(list(np.linspace(0.1,1,100)),max_dfList)\n",
    "plt.xlabel('TF-IDF max document frequency')\n",
    "plt.ylabel('SVC accuracy score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(max_dfList,list(np.linspace(0.1,0.5,40))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f990c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVCpipeline = Pipeline( [(\n",
    "    'tfidf',TfidfVectorizer(max_df=0.2641025641025641)), \n",
    "    ('svc',SVC())])\n",
    "SVCpipeline.fit(X_train, Y_train)\n",
    "accuracy_score(Y_test, SVCpipeline.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c23f978",
   "metadata": {},
   "source": [
    "## Linear SVC evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the confusion matrix\n",
    "cf_matrix =confusion_matrix(Y_test, LSVC_Yguess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55607fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, LSVC_Yguess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73324abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408bd2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "\n",
    "ax.set_title('Linear SVC Confusion Matrix, Accuracy Score: %.3f' % accuracy_score(Y_test, LSVC_Yguess));\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6138242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision_score(Y_test, LSVC_Yguess, pos_label=1),\n",
    "      recall_score(Y_test, LSVC_Yguess, pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64d3c76",
   "metadata": {},
   "source": [
    "##  SVC evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44dfe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix =confusion_matrix(Y_test, SVCpipeline.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b723a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, SVCpipeline.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff8f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cef805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6138242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision score of SVC:\",precision_score(Y_test, SVCpipeline.predict(X_test), pos_label=1),\n",
    "      \"\\nRecall score of SVC:\",recall_score(Y_test, SVCpipeline.predict(X_test), pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee3374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, SVCpipeline.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d35cc88",
   "metadata": {},
   "source": [
    "# Precision/Recall curves comparison for Linear SVC and SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c14e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = LSVCpipeline.decision_function(X_test)\n",
    "\n",
    "precs, recs, _ = precision_recall_curve(Y_test, scores, pos_label=1)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(recs, precs)\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')\n",
    "plt.axis([0, 1, 0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e8365",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [LSVCpipeline,SVCpipeline]\n",
    "\n",
    "APs = []\n",
    "plt.figure(figsize=(5,5))\n",
    "for pipeline in pipelines:\n",
    "    scores = pipeline.decision_function(X_test)\n",
    "    precisions, recalls, _ = precision_recall_curve(Y_test, scores, pos_label=1)\n",
    "    \n",
    "    plt.plot(recalls, precisions)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    \n",
    "plt.legend(['Linear SVC','SVC']);\n",
    "plt.title('Precision/Recall curve of Linear SVC and SVC\\n' )\n",
    "plt.axis([0, 1, 0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f82e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pipeline in pipelines:\n",
    "    scores = pipeline.decision_function(X_test)\n",
    "    precisions, recalls, _ = precision_recall_curve(Y_test, scores, pos_label=1)\n",
    "    \n",
    "    plt.plot(recalls, precisions)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    \n",
    "# leg_labels = [ '{:3}: AP = {:.3f}'.format(n, AP) for n, AP in APs ]\n",
    "plt.legend(['Linear SVC','SVC']);\n",
    "plt.title('A zoom-in the Precision/Recall curve of Linear SVC and SVC\\n' )\n",
    "plt.axis([0.8, 1, 0.8, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460e43c",
   "metadata": {},
   "source": [
    "# LSVC Misclassified instances sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c369aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf= test \n",
    "tempdf['LSVC_predicted'] = LSVC_Yguess\n",
    "tempdf[tempdf.LSVC_predicted != tempdf.annotation].head().review.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ae0930",
   "metadata": {},
   "source": [
    "# SVC Misclassified instances sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d3da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf['SVC_predicted'] =SVCpipline.predict(X_test)\n",
    "tempdf[tempdf.SVC_predicted != tempdf.annotation].head().review.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e996b5",
   "metadata": {},
   "source": [
    "# Features importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65834d8",
   "metadata": {},
   "source": [
    "# LSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = LSVCpipeline.named_steps[\"tfidf\"].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5e2458",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = LSVCpipeline.named_steps[\"linearsvc\"].coef_.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35843fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a942410",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = zip(feature_names, coefs)\n",
    "df = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
    "# Sort the features by the absolute value of their coefficient\n",
    "df[\"abs_value\"] = df[\"value\"].apply(lambda x: abs(x))\n",
    "df[\"colors\"] = df[\"value\"].apply(lambda x: \"green\" if x > 0 else \"red\")\n",
    "df = df.sort_values(\"abs_value\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39261d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style( {\"grid.color\": \".8\", \"grid.linestyle\": \":\"})\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 6))\n",
    "sns.barplot(y=\"feature\",\n",
    "            x=\"value\",\n",
    "            data=df.head(30),\n",
    "           palette=df.head(30)[\"colors\"])\n",
    "ax.set_title(\"Top 30 words (features) contributing to \\nthe Linear SVC classification performance\", fontsize=12)\n",
    "ax.set_ylabel(\"Feature Name\", fontsize=12)\n",
    "ax.set_xlabel(\"Coefficient\", fontsize=12)\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
